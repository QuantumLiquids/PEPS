// SPDX-License-Identifier: LGPL-3.0-only

/*
* Author: Hao-Xin Wang<wanghaoxin1996@gmail.com>
* Creation Date: 2025-01-27
*
* Description: QuantumLiquids/PEPS project. Optimizer for VMC PEPS.
*/

#ifndef QLPEPS_ALGORITHM_VMC_UPDATE_OPTIMIZER_H
#define QLPEPS_ALGORITHM_VMC_UPDATE_OPTIMIZER_H

#include <vector>
#include <memory>
#include <functional>
#include "qlpeps/two_dim_tn/tps/split_index_tps.h"
#include "qlpeps/optimizer/optimizer_params.h"
#include "qlpeps/optimizer/spike_detection.h"
#include "qlpeps/utility/conjugate_gradient_solver.h"
#include "qlpeps/optimizer/stochastic_reconfiguration_smatrix.h"

namespace qlpeps {

// Narrow import: prefer direct symbol using over local alias
using qlten::QLTensor;

/**
 * @brief Optimizer for VMC PEPS that handles different optimization strategies with MPI support
 * 
 * This class provides a unified interface for different optimization strategies.
 * It supports line search and iterative optimization, with or without energy error support.
 * 
 * The optimization strategies are:
 * 1. SGD (with momentum and Nesterov acceleration)
 * 2. AdaGrad (Adaptive Gradient)
 * 3. Stochastic reconfiguration (natural gradient)
 * 4. Bounded gradient element update
 * 5. Adam (with AdamW-style decoupled weight decay)
 * 6. L-BFGS (planned)
 * 
 * âš ï¸ CRITICAL MPI RESPONSIBILITY SEPARATION:
 * 
 * ã€CORE PRINCIPLEã€‘: Clear MPI responsibility separation between state distribution and algorithm computation.
 * 
 * This design eliminates triple redundant broadcasts and follows "good taste" principles:
 * "Good taste is about eliminating special cases and making the normal case work correctly."
 * 
 * â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 * â”‚   Optimizer     â”‚    â”‚ Energy Evaluator â”‚    â”‚  VMC Executor   â”‚
 * â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
 * â”‚ â€¢ Algorithm logicâ”‚â”€â”€â”€â–¶â”‚ â€¢ Receives state â”‚    â”‚ â€¢ Final sync    â”‚
 * â”‚ â€¢ SR uses MPI   â”‚    â”‚ â€¢ Broadcasts     â”‚    â”‚ â€¢ End guarantee â”‚
 * â”‚ â€¢ NO state bcastâ”‚    â”‚ â€¢ Manages MC     â”‚    â”‚ â€¢ Cleanup       â”‚
 * â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 *                               â”‚
 *                               â–¼
 *                       All ranks synchronized
 *                       for Monte Carlo sampling
 * 
 * ã€RESPONSIBILITY MATRIXã€‘:
 * | Component         | Responsibility              | MPI Behavior                    |
 * |-------------------|----------------------------|---------------------------------|
 * | Optimizer         | Algorithm logic & updates  | âœ… SR/CG solver, âŒ NO state bcast|
 * | Energy Evaluator  | MC sampling coordination   | âœ… Sole state broadcast owner    |
 * | VMC Executor      | High-level orchestration   | âœ… Final state guarantee         |
 * 
 * ã€MPI DATA DISTRIBUTIONã€‘:
 * 
 * INPUT (to energy_evaluator):
 * - current_state: Valid ONLY on master rank (optimizer output)
 * 
 * OUTPUT (from energy_evaluator):  
 * - energy: Valid on ALL ranks (broadcast by energy_evaluator)
 * - gradient: Valid ONLY on master rank (gathered by energy_evaluator)
 * - energy_error: Valid ONLY on master rank
 * 
 * INTERNAL STATE:
 * - algorithm_state (velocity, accumulated_gradients): Master rank ONLY
 * - optimization_statistics: Master rank ONLY
 * 
 * OUTPUT:
 * - optimized_state: Valid on all ranks (final broadcast by executor)
 * - trajectories: Master rank ONLY
 * 
 * ã€ITERATION FLOWã€‘:
 * 1. Optimizer updates state on master rank           â† NO state broadcast
 * 2. SR algorithm: MPI-distributed CG solving         â† Optimizer internal MPI
 * 3. Energy evaluator receives state (master only)    â† NO state broadcast yet
 * 4. Energy evaluator broadcasts for MC sampling      â† SINGLE state broadcast  
 * 5. Distributed Monte Carlo execution                â† All ranks
 * 6. Energy evaluator gathers gradients to master     â† Standard gather
 * 7. Energy evaluator broadcasts energy to all ranks  â† Standard broadcast
 * 8. Return to step 1                                 â† Loop continues
 * 
 * ã€DESIGN BENEFITSã€‘:
 * - 67% reduction in state broadcast overhead (3â†’1 broadcasts per iteration)
 * - Clear responsibility separation (single responsibility principle)
 * - Eliminates "special cases" and redundant MPI calls
 * - Better scalability for large MPI configurations
 * 
 * THREAD SAFETY:
 * - All gradient updates are performed only on master rank
 * - Updated states are broadcast to all ranks after each iteration
 * - This ensures deterministic behavior across different MPI configurations
 * 
 * @tparam TenElemT Tensor element type
 * @tparam QNT Quantum number type
 */
template<typename TenElemT, typename QNT>
class Optimizer {
 public:
  using Tensor = QLTensor<TenElemT, QNT>;
  using SITPST = SplitIndexTPS<TenElemT, QNT>;
  using WaveFunctionT = SITPST;
  
  struct OptimizationResult {
    WaveFunctionT optimized_state;
    double final_energy;
    double min_energy;
    std::vector<TenElemT> energy_trajectory;
    std::vector<double> energy_error_trajectory;
    std::vector<double> gradient_norms;
    size_t total_iterations;
    bool converged;
    SpikeStatistics spike_stats;   ///< Spike detection statistics for the run
  };

  struct OptimizationCallback {
    std::function<void(size_t iteration, double energy, double energy_error, double gradient_norm)> 
        on_iteration;
    std::function<void(const WaveFunctionT& state, double energy)> 
        on_best_state_found;
    std::function<bool(size_t iteration, double energy, double energy_error)> 
        should_stop;
  };

  Optimizer(const OptimizerParams& params, 
            const MPI_Comm& comm,
            int rank,
            int mpi_size);

  /**
   * @brief Perform line search optimization
   * 
   * @param initial_state Initial TPS state
   * @param energy_evaluator Function to evaluate energy and gradient
   * @param callback Optional callback for monitoring progress
   * @return Optimization result
   */
  OptimizationResult LineSearchOptimize(
      const WaveFunctionT& initial_state,
      std::function<std::pair<TenElemT, WaveFunctionT>(const WaveFunctionT&)> energy_evaluator,
      const OptimizationCallback& callback = OptimizationCallback{});

  /**
   * @brief Perform line search optimization with energy error support
   * 
   * @param initial_state Initial TPS state
   * @param energy_evaluator Function to evaluate energy, gradient, and error
   * @param callback Optional callback for monitoring progress
   * @return Optimization result
   */
  OptimizationResult LineSearchOptimize(
      const WaveFunctionT& initial_state,
      std::function<std::tuple<TenElemT, WaveFunctionT, double>(const WaveFunctionT&)> energy_evaluator,
      const OptimizationCallback& callback = OptimizationCallback{});

  /**
   * @brief Perform iterative optimization with energy error support
   * 
   * @param initial_state Initial TPS state
   * @param energy_evaluator Function to evaluate energy, gradient, and error
   * @param callback Optional callback for monitoring progress
   * @param Ostar_samples Optional O^*(S) samples for stochastic reconfiguration
   * @param Ostar_mean Optional average O^* tensor for stochastic reconfiguration
   * @return Optimization result
   */
  OptimizationResult IterativeOptimize(
      const WaveFunctionT& initial_state,
      std::function<std::tuple<TenElemT, WaveFunctionT, double>(const WaveFunctionT&)> energy_evaluator,
      const OptimizationCallback& callback = OptimizationCallback{},
      const std::vector<WaveFunctionT>* Ostar_samples = nullptr,
      const WaveFunctionT* Ostar_mean = nullptr);



  /**
   * @brief Calculate natural gradient using stochastic reconfiguration
   * 
   * âœ… MPI COMMUNICATION REQUIRED: This function DOES use MPI for distributed CG solving!
   * 
   * Unlike state update functions, SR natural gradient calculation requires distributed
   * computation across all ranks:
   * - Master rank coordinates CG iterations 
   * - All ranks participate in matrix-vector multiplications
   * - Broadcast/gather operations for CG algorithm convergence
   * 
   * This is algorithm-internal MPI communication, NOT state distribution.
   * 
   * @param gradient Standard gradient (valid ONLY on master rank)
   * @param Ostar_samples O^*(S) tensor samples (distributed across ranks)
   * @param Ostar_mean Average O^* tensor (valid ONLY on master rank)
   * @param init_guess Initial guess for conjugate gradient solver
   * @return Natural gradient and number of CG iterations (valid ONLY on master rank)
   */
  std::pair<WaveFunctionT, size_t> CalculateNaturalGradient(
      const WaveFunctionT& gradient,
      const std::vector<WaveFunctionT>& Ostar_samples,
      const WaveFunctionT& Ostar_mean,
      const WaveFunctionT& init_guess);

  /**
   * @brief Apply stochastic reconfiguration update
   * 
   * @param current_state Current TPS state
   * @param gradient Standard gradient
   * @param Ostar_samples O^*(S) tensor samples
   * @param Ostar_mean Average O^* tensor
   * @param step_length Step length
   * @param init_guess Initial guess for CG solver
   * @param normalize Whether to normalize the natural gradient
   * @return Updated state, natural gradient norm, and CG iterations
   */
  std::tuple<WaveFunctionT, double, size_t> StochasticReconfigurationUpdate(
      const WaveFunctionT& current_state,
      const WaveFunctionT& gradient,
      const std::vector<WaveFunctionT>& Ostar_samples,
      const WaveFunctionT& Ostar_mean,
      double step_length,
      const WaveFunctionT& init_guess,
      bool normalize = false);

  /**
   * @brief Apply bounded gradient element update
   * 
   * ğŸš« MPI RESPONSIBILITY: This function does NOT broadcast the updated state!
   * Energy evaluator handles all state distribution for Monte Carlo sampling.
   * 
   * @param current_state Current TPS state (valid on all ranks)
   * @param gradient Gradient (valid ONLY on master rank)
   * @param step_length Step length
   * @return Updated TPS state (valid ONLY on master rank)
   */
  WaveFunctionT BoundedGradientUpdate(const WaveFunctionT& current_state,
                               const WaveFunctionT& gradient,
                               double step_length);

  /**
   * @brief Apply AdaGrad update with adaptive learning rates
   * 
   * ğŸš« MPI RESPONSIBILITY: This function does NOT broadcast the updated state!
   * Energy evaluator handles all state distribution for Monte Carlo sampling.
   * 
   * @param current_state Current TPS state (valid on all ranks)
   * @param gradient Gradient (valid ONLY on master rank)
   * @param step_length Step length (base learning rate)
   * @return Updated TPS state (valid ONLY on master rank)
   */
  WaveFunctionT AdaGradUpdate(const WaveFunctionT& current_state,
                       const WaveFunctionT& gradient,
                       double step_length);

  /**
   * @brief Apply Adam update with bias-corrected moment estimates
   * 
   * MPI RESPONSIBILITY: This function does NOT broadcast the updated state!
   * Energy evaluator handles all state distribution for Monte Carlo sampling.
   * 
   * Algorithm:
   *   m_t = Î²â‚ m_{t-1} + (1-Î²â‚) g_t
   *   v_t = Î²â‚‚ v_{t-1} + (1-Î²â‚‚) g_tÂ²
   *   mÌ‚_t = m_t / (1 - Î²â‚^t)
   *   vÌ‚_t = v_t / (1 - Î²â‚‚^t)
   *   Î¸_{t+1} = Î¸_t - Î± mÌ‚_t / (âˆšvÌ‚_t + Îµ)
   * 
   * With optional decoupled weight decay (AdamW):
   *   Î¸_{t+1} = (1 - Î±Î») Î¸_t - Î± mÌ‚_t / (âˆšvÌ‚_t + Îµ)
   * 
   * @param current_state Current TPS state (valid on all ranks)
   * @param gradient Gradient (valid ONLY on master rank)
   * @param step_length Step length (learning rate)
   * @param params Adam parameters (beta1, beta2, epsilon, weight_decay)
   * @return Updated TPS state (valid ONLY on master rank)
   */
  WaveFunctionT AdamUpdate(const WaveFunctionT& current_state,
                           const WaveFunctionT& gradient,
                           double step_length,
                           const AdamParams& params);

  /**
   * @brief Get current learning rate based on iteration and scheduler
   * 
   * @param iteration Current optimization iteration
   * @param current_energy Current energy value (for energy-aware schedulers)
   * @return Learning rate for this iteration
   */
  double GetCurrentLearningRate(size_t iteration, double current_energy = 0.0) const;

  // =============================================================================
  // BACKWARD COMPATIBILITY: Static methods for legacy VMC PEPS code
  // =============================================================================
  
  // Legacy enum-based helper methods removed - use OptimizerParams.IsAlgorithm<T>() instead

  /**
   * @brief Get spike detection statistics from the last optimization run.
   */
  const SpikeStatistics &GetSpikeStats() const { return spike_stats_; }

  /**
   * @brief Check if optimization should stop based on convergence criteria
   * 
   * @param current_energy Current energy value
   * @param previous_energy Previous energy value  
   * @param gradient_norm Current gradient norm
   * @param iterations_without_improvement Number of iterations without improvement
   * @return True if optimization should stop
   */
  bool ShouldStop(double current_energy, double previous_energy, double gradient_norm, 
                  size_t iterations_without_improvement);

  /**
   * @brief Clear up intermediate data and reset optimization state
   * 
   * This method should be called after optimization is complete to:
   * - Free memory used by intermediate data structures
   * - Reset algorithm-specific state variables
   * - Prepare for potential future optimizations
   * 
   * Note: This method is automatically called at the end of optimization methods
   * (LineSearchOptimize, IterativeOptimize). Users typically don't need to call
   * it manually unless they want to explicitly clean up state between operations.
   */
  void ClearUp();

 private:
  OptimizerParams params_;
  MPI_Comm comm_;
  int rank_;
  int mpi_size_;
  
  // No RNG state needed inside Optimizer; stochasticity belongs to Monte Carlo components.

  // AdaGrad state
  WaveFunctionT accumulated_gradients_;
  bool adagrad_initialized_;
  
  // SGD Momentum state
  WaveFunctionT velocity_;
  bool sgd_momentum_initialized_;

  // Adam state (master rank ONLY)
  WaveFunctionT first_moment_;      // m_t: first moment estimate
  WaveFunctionT second_moment_;     // v_t: second moment estimate
  size_t adam_timestep_;            // t: iteration counter for bias correction
  bool adam_initialized_;

  // Spike detection state (master rank ONLY)
  EMATracker ema_energy_;
  EMATracker ema_error_;
  EMATracker ema_grad_norm_;
  EMATracker ema_ngrad_norm_;
  double prev_energy_ = 0.0;
  SpikeStatistics spike_stats_;

  // S4 rollback state (master rank ONLY, allocated only when enable_rollback)
  WaveFunctionT prev_accepted_state_;
  bool has_prev_state_ = false;

  // Spike detection and recovery methods (master rank evaluates, then broadcasts)
  SpikeSignal DetectS1S2_(double error, double grad_norm) const;
  SpikeSignal DetectS3_(double ngrad_norm, size_t sr_iters) const;
  SpikeSignal DetectS4_(double energy) const;
  SpikeAction DecideAction_(SpikeSignal signal, size_t attempts, size_t step) const;
  SpikeAction BroadcastAction_(SpikeAction action);
  void LogSpikeEvent_(size_t step, size_t attempt, SpikeSignal signal,
                      SpikeAction action, double value, double threshold);

  // Checkpoint
  void SaveCheckpoint_(const WaveFunctionT& state, size_t step,
                       const std::vector<TenElemT>& energy_traj,
                       const std::vector<double>& error_traj);

  // Helper methods
  void LogOptimizationStep(size_t iteration,
                          double energy,
                          double energy_error,
                          double gradient_norm,
                          double step_length = 0.0,
                          const std::vector<double>& accept_rates = {},
                          size_t sr_iterations = 0,
                          double sr_natural_grad_norm = 0.0,
                          double energy_eval_time = 0.0,
                          double update_time = 0.0);
  
  template<typename UpdateFunc>
  OptimizationResult PerformOptimization(
      const WaveFunctionT& initial_state,
      std::function<std::pair<TenElemT, WaveFunctionT>(const WaveFunctionT&)> energy_evaluator,
      UpdateFunc update_func,
      const OptimizationCallback& callback);

  // Algorithm-specific update methods
  
  /**
   * @brief SGD with momentum and Nesterov acceleration support
   * 
   * ğŸš« MPI RESPONSIBILITY: This function does NOT broadcast the updated state!
   * Energy evaluator handles all state distribution for Monte Carlo sampling.
   * 
   * Unified implementation naturally handles all SGD variants:
   * - momentum = 0.0: reduces to vanilla SGD 
   * - momentum > 0.0 + nesterov = false: standard momentum SGD
   * - momentum > 0.0 + nesterov = true: Nesterov accelerated gradient
   */
  WaveFunctionT SGDUpdate(const WaveFunctionT& current_state,
                         const WaveFunctionT& gradient,
                         double step_length,
                         const SGDParams& params);
  
 };



} // namespace qlpeps

#include "qlpeps/optimizer/optimizer_impl.h"

#endif // QLPEPS_ALGORITHM_VMC_UPDATE_OPTIMIZER_H 